{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# ğŸ§  Neural Proof Assistant - Training Notebook\n",
        "\n",
        "This notebook trains a proof technique classifier using:\n",
        "1. **Weak Supervision** - Labeling functions generate training data\n",
        "2. **Sentence Transformers** - Pre-trained embeddings for semantic understanding\n",
        "3. **Classifier** - Learns to generalize beyond the rules\n",
        "\n",
        "**Output:** `classifier.pkl` and `label_encoder.pkl` to download and use in your FastAPI backend."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 0: Install Dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torch in /opt/homebrew/lib/python3.11/site-packages (2.9.1)\n",
            "Collecting torchvision\n",
            "  Downloading torchvision-0.24.1-cp311-cp311-macosx_11_0_arm64.whl.metadata (5.9 kB)\n",
            "Collecting torchaudio\n",
            "  Downloading torchaudio-2.9.1-cp311-cp311-macosx_11_0_arm64.whl.metadata (6.9 kB)\n",
            "Requirement already satisfied: filelock in /opt/homebrew/lib/python3.11/site-packages (from torch) (3.20.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /Users/aditya/Library/Python/3.11/lib/python/site-packages (from torch) (4.14.1)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /opt/homebrew/lib/python3.11/site-packages (from torch) (1.14.0)\n",
            "Requirement already satisfied: networkx>=2.5.1 in /opt/homebrew/lib/python3.11/site-packages (from torch) (3.6)\n",
            "Requirement already satisfied: jinja2 in /Users/aditya/Library/Python/3.11/lib/python/site-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec>=0.8.5 in /opt/homebrew/lib/python3.11/site-packages (from torch) (2025.10.0)\n",
            "Requirement already satisfied: numpy in /opt/homebrew/lib/python3.11/site-packages (from torchvision) (1.26.4)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /opt/homebrew/lib/python3.11/site-packages (from torchvision) (12.0.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/homebrew/lib/python3.11/site-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /Users/aditya/Library/Python/3.11/lib/python/site-packages (from jinja2->torch) (3.0.2)\n",
            "Downloading torchvision-0.24.1-cp311-cp311-macosx_11_0_arm64.whl (1.9 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m24.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading torchaudio-2.9.1-cp311-cp311-macosx_11_0_arm64.whl (807 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m807.3/807.3 kB\u001b[0m \u001b[31m34.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: torchvision, torchaudio\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m2/2\u001b[0m [torchaudio]2\u001b[0m [torchaudio]\n",
            "\u001b[1A\u001b[2KSuccessfully installed torchaudio-2.9.1 torchvision-0.24.1\n",
            "\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.1.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.3\u001b[0m\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49m/opt/homebrew/opt/python@3.11/bin/python3.11 -m pip install --upgrade pip\u001b[0m\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "%pip install --upgrade torch torchvision torchaudio"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.1.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.3\u001b[0m\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49m/opt/homebrew/opt/python@3.11/bin/python3.11 -m pip install --upgrade pip\u001b[0m\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "%pip install sentence-transformers scikit-learn pandas numpy --upgrade -q"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 1: Define Labeling Functions\n",
        "\n",
        "These are the same labeling functions from your FastAPI backend. They generate weak labels for training."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… Labeling function classes defined\n"
          ]
        }
      ],
      "source": [
        "import re\n",
        "from enum import IntEnum\n",
        "from typing import List\n",
        "\n",
        "class ProofTechnique(IntEnum):\n",
        "    ABSTAIN = -1\n",
        "    DIRECT = 0\n",
        "    CONTRADICTION = 1\n",
        "    INDUCTION = 2\n",
        "    CONTRAPOSITIVE = 3\n",
        "    CONSTRUCTION = 4\n",
        "    CASES = 5\n",
        "    EXHAUSTION = 6\n",
        "\n",
        "TECHNIQUE_NAMES = {\n",
        "    0: \"Direct Proof\",\n",
        "    1: \"Proof by Contradiction\",\n",
        "    2: \"Mathematical Induction\",\n",
        "    3: \"Contrapositive\",\n",
        "    4: \"Proof by Construction\",\n",
        "    5: \"Proof by Cases\",\n",
        "    6: \"Proof by Exhaustion\"\n",
        "}\n",
        "\n",
        "class LabelingFunction:\n",
        "    def __init__(self, name: str, weight: float = 1.0):\n",
        "        self.name = name\n",
        "        self.weight = weight\n",
        "\n",
        "    def __call__(self, text: str) -> int:\n",
        "        raise NotImplementedError\n",
        "\n",
        "\n",
        "class KeywordLF(LabelingFunction):\n",
        "    def __init__(self, name: str, keywords: List[str], label: int,\n",
        "                 negative_keywords: List[str] = None, weight: float = 1.0):\n",
        "        super().__init__(name, weight)\n",
        "        self.keywords = [k.lower() for k in keywords]\n",
        "        self.negative_keywords = [k.lower() for k in (negative_keywords or [])]\n",
        "        self.label = label\n",
        "\n",
        "    def __call__(self, text: str) -> int:\n",
        "        text_lower = text.lower()\n",
        "        for neg in self.negative_keywords:\n",
        "            if neg in text_lower:\n",
        "                return ProofTechnique.ABSTAIN\n",
        "        if any(kw in text_lower for kw in self.keywords):\n",
        "            return self.label\n",
        "        return ProofTechnique.ABSTAIN\n",
        "\n",
        "\n",
        "class PatternLF(LabelingFunction):\n",
        "    def __init__(self, name: str, patterns: List[str], label: int, weight: float = 1.0):\n",
        "        super().__init__(name, weight)\n",
        "        self.patterns = [re.compile(p, re.IGNORECASE) for p in patterns]\n",
        "        self.label = label\n",
        "\n",
        "    def __call__(self, text: str) -> int:\n",
        "        for pattern in self.patterns:\n",
        "            if pattern.search(text):\n",
        "                return self.label\n",
        "        return ProofTechnique.ABSTAIN\n",
        "\n",
        "\n",
        "class StructuralLF(LabelingFunction):\n",
        "    def __init__(self, name: str, required_sections: List[str], label: int, weight: float = 1.0):\n",
        "        super().__init__(name, weight)\n",
        "        self.required_sections = [s.lower() for s in required_sections]\n",
        "        self.label = label\n",
        "\n",
        "    def __call__(self, text: str) -> int:\n",
        "        text_lower = text.lower()\n",
        "        found_count = sum(1 for section in self.required_sections if section in text_lower)\n",
        "        if found_count >= len(self.required_sections) * 0.66:\n",
        "            return self.label\n",
        "        return ProofTechnique.ABSTAIN\n",
        "\n",
        "print(\"âœ… Labeling function classes defined\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… Defined 19 labeling functions\n"
          ]
        }
      ],
      "source": [
        "# Define all labeling functions\n",
        "LABELING_FUNCTIONS = [\n",
        "    # === DIRECT PROOF ===\n",
        "    KeywordLF(\"direct_keywords\", [\"we have\", \"it follows that\", \"thus we see\", \"clearly\"],\n",
        "              ProofTechnique.DIRECT,\n",
        "              negative_keywords=[\"contradiction\", \"contradicts\", \"suppose not\", \"induction\", \"base case\"],\n",
        "              weight=0.8),\n",
        "    PatternLF(\"direct_pattern\", [r\"assume\\s+.{5,50}\\.\\s*then\", r\"let\\s+.{3,30}\\s+be\\s+.{3,30}\\.\\s*then\"],\n",
        "              ProofTechnique.DIRECT, weight=1.0),\n",
        "\n",
        "    # === CONTRADICTION ===\n",
        "    KeywordLF(\"contradiction_explicit\", [\"contradiction\", \"contradicts\", \"contradicting\"],\n",
        "              ProofTechnique.CONTRADICTION, weight=1.5),\n",
        "    KeywordLF(\"contradiction_absurd\", [\"absurd\", \"impossible\", \"cannot be\"],\n",
        "              ProofTechnique.CONTRADICTION, weight=1.2),\n",
        "    PatternLF(\"contradiction_pattern_suppose\",\n",
        "              [r\"suppose\\s+(not|.*\\s+not\\s+)\", r\"assume\\s+(for\\s+)?contradiction\",\n",
        "               r\"assume\\s+the\\s+contrary\", r\"for\\s+the\\s+sake\\s+of\\s+contradiction\",\n",
        "               r\"suppose.*rational\", r\"suppose.*is\\s+rational\"],\n",
        "              ProofTechnique.CONTRADICTION, weight=1.3),\n",
        "    PatternLF(\"contradiction_pattern_derive\",\n",
        "              [r\"this\\s+(is\\s+a\\s+)?contradiction\", r\"which\\s+contradicts\",\n",
        "               r\"contradicting\\s+(our|the)\\s+(assumption|hypothesis)\", r\"this\\s+is\\s+absurd\",\n",
        "               r\"but\\s+this\\s+contradicts\", r\"this\\s+contradicts\"],\n",
        "              ProofTechnique.CONTRADICTION, weight=1.6),\n",
        "\n",
        "    # === INDUCTION ===\n",
        "    KeywordLF(\"induction_explicit\", [\"induction\", \"inductive\"],\n",
        "              ProofTechnique.INDUCTION, weight=1.3),\n",
        "    StructuralLF(\"induction_structure\", [\"base case\", \"inductive step\", \"inductive hypothesis\"],\n",
        "                 ProofTechnique.INDUCTION, weight=1.5),\n",
        "    PatternLF(\"induction_pattern_base\",\n",
        "              [r\"base\\s+case.*n\\s*=\\s*[01]\", r\"for\\s+n\\s*=\\s*[01].*holds\", r\"when\\s+n\\s*=\\s*[01]\"],\n",
        "              ProofTechnique.INDUCTION, weight=1.2),\n",
        "    PatternLF(\"induction_pattern_step\",\n",
        "              [r\"inductive\\s+step\", r\"assume\\s+(true\\s+)?for\\s+n\\s*=\\s*k\",\n",
        "               r\"by\\s+(the\\s+)?inductive\\s+hypothesis\"],\n",
        "              ProofTechnique.INDUCTION, weight=1.4),\n",
        "\n",
        "    # === CONTRAPOSITIVE ===\n",
        "    KeywordLF(\"contrapositive_explicit\", [\"contrapositive\", \"contrapositively\"],\n",
        "              ProofTechnique.CONTRAPOSITIVE, weight=1.4),\n",
        "    PatternLF(\"contrapositive_pattern\",\n",
        "              [r\"prove\\s+the\\s+contrapositive\", r\"by\\s+contrapositive\",\n",
        "               r\"if\\s+not.*then\\s+not\"],\n",
        "              ProofTechnique.CONTRAPOSITIVE, weight=1.3),\n",
        "\n",
        "    # === CONSTRUCTION ===\n",
        "    KeywordLF(\"construction_explicit\", [\"construct\", \"constructive\", \"exhibit\"],\n",
        "              ProofTechnique.CONSTRUCTION,\n",
        "              negative_keywords=[\"construct a contradiction\"], weight=1.1),\n",
        "    PatternLF(\"construction_pattern\",\n",
        "              [r\"we\\s+construct\", r\"we\\s+exhibit\", r\"consider\\s+the\\s+(following\\s+)?example\",\n",
        "               r\"such\\s+a.{1,20}exists.*namely\"],\n",
        "              ProofTechnique.CONSTRUCTION, weight=1.0),\n",
        "\n",
        "    # === CASES ===\n",
        "    KeywordLF(\"cases_explicit\", [\"case 1\", \"case 2\", \"case i\", \"case ii\"],\n",
        "              ProofTechnique.CASES, weight=1.3),\n",
        "    PatternLF(\"cases_pattern\",\n",
        "              [r\"we\\s+(consider|divide)\\s+(into\\s+)?(two|three|several)\\s+cases\",\n",
        "               r\"there\\s+are\\s+(two|three|several)\\s+cases\",\n",
        "               r\"case\\s+\\d+\\s*:\", r\"in\\s+(the\\s+)?(first|second)\\s+case\"],\n",
        "              ProofTechnique.CASES, weight=1.2),\n",
        "    PatternLF(\"cases_structure\", [r\"either.*or\", r\"suppose.*is\\s+(even|odd)\"],\n",
        "              ProofTechnique.CASES, weight=0.9),\n",
        "\n",
        "    # === EXHAUSTION ===\n",
        "    PatternLF(\"exhaustion_pattern\",\n",
        "              [r\"check\\s+(each|all|every)\", r\"by\\s+exhaustion\",\n",
        "               r\"checking\\s+all\\s+(possible\\s+)?cases\", r\"we\\s+enumerate\"],\n",
        "              ProofTechnique.EXHAUSTION, weight=1.2),\n",
        "    KeywordLF(\"exhaustion_keywords\", [\"exhaustively\", \"finite check\", \"brute force\"],\n",
        "              ProofTechnique.EXHAUSTION, weight=1.1),\n",
        "]\n",
        "\n",
        "print(f\"âœ… Defined {len(LABELING_FUNCTIONS)} labeling functions\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 2: Create Training Dataset\n",
        "\n",
        "We'll create sample proofs and use the labeling functions to generate weak labels."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… Sample proofs defined\n",
            "   Proof by Contradiction: 12 examples\n",
            "   Mathematical Induction: 10 examples\n",
            "   Proof by Cases: 10 examples\n",
            "   Proof by Construction: 10 examples\n",
            "   Contrapositive: 8 examples\n",
            "   Direct Proof: 8 examples\n",
            "   Proof by Exhaustion: 8 examples\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "# Sample proofs for each technique (you can add more!)\n",
        "SAMPLE_PROOFS = {\n",
        "    ProofTechnique.CONTRADICTION: [\n",
        "        \"Suppose âˆš2 is rational. Then âˆš2 = a/b where a, b have no common factors. Squaring, aÂ² = 2bÂ². This means a is even. Write a = 2k. Then bÂ² = 2kÂ², so b is also even. This contradicts our assumption. Therefore âˆš2 is irrational.\",\n",
        "        \"Assume for contradiction that there are finitely many primes pâ‚, pâ‚‚, ..., pâ‚™. Consider N = pâ‚pâ‚‚...pâ‚™ + 1. N is not divisible by any páµ¢. This is a contradiction since every integer > 1 has a prime factor.\",\n",
        "        \"Suppose the square root of 3 is rational. Then âˆš3 = a/b in lowest terms. So 3bÂ² = aÂ², meaning aÂ² is divisible by 3. Thus a is divisible by 3. Write a = 3k. Then 3bÂ² = 9kÂ², so bÂ² = 3kÂ². But then b is also divisible by 3, contradicting lowest terms.\",\n",
        "        \"Assume there exists a smallest positive rational number r. Consider r/2. This is positive and rational, but smaller than r. This contradicts our assumption that r was smallest.\",\n",
        "        \"Suppose âˆš5 is rational, so âˆš5 = p/q with gcd(p,q) = 1. Then 5qÂ² = pÂ². Thus 5 divides pÂ², so 5 divides p. Let p = 5k. Then 5qÂ² = 25kÂ², giving qÂ² = 5kÂ². So 5 divides q. This contradicts gcd(p,q) = 1.\",\n",
        "        \"For the sake of contradiction, assume logâ‚‚(3) is rational. Then logâ‚‚(3) = p/q for integers p, q. So 2^(p/q) = 3, meaning 2^p = 3^q. But 2^p is even and 3^q is odd. This is a contradiction.\",\n",
        "        \"Suppose there is a largest prime number P. Consider N = P! + 1. For any prime p â‰¤ P, we have p | P!, so p âˆ¤ N. Thus N has a prime factor greater than P. This contradicts P being largest.\",\n",
        "        \"Assume âˆš6 is rational. Write âˆš6 = a/b in lowest terms. Then 6bÂ² = aÂ², so aÂ² is even, hence a is even. Let a = 2k. Then 6bÂ² = 4kÂ², so 3bÂ² = 2kÂ². Thus bÂ² is even, so b is even. This contradicts a/b being in lowest terms.\",\n",
        "        \"Suppose, seeking a contradiction, that there exists an integer that is both even and odd. Then n = 2k and n = 2m + 1 for some integers k, m. So 2k = 2m + 1, giving 2(k-m) = 1. But 2 does not divide 1. Contradiction.\",\n",
        "        \"Assume for contradiction that 0 = 1. Then for any x, we have x = xÂ·1 = xÂ·0 = 0. But this means all numbers equal 0, which is absurd.\",\n",
        "        \"We proceed by contradiction. Suppose there is a rational solution to xÂ² = 2. Let x = p/q in lowest terms. Then pÂ² = 2qÂ². So pÂ² is even, meaning p is even. Write p = 2r. Then 4rÂ² = 2qÂ², so qÂ² = 2rÂ². Thus q is even. But this contradicts p/q being in lowest terms.\",\n",
        "        \"Suppose that the set of real numbers is countable. By Cantor's diagonal argument, we can construct a real number not in our list. This is a contradiction, so the reals are uncountable.\",\n",
        "    ],\n",
        "\n",
        "    ProofTechnique.INDUCTION: [\n",
        "        \"We prove by induction that 1 + 2 + ... + n = n(n+1)/2. Base case: For n = 1, we have 1 = 1(2)/2 = 1. âœ“ Inductive step: Assume true for n = k. Then 1 + 2 + ... + k + (k+1) = k(k+1)/2 + (k+1) = (k+1)(k+2)/2. By induction, the formula holds for all n.\",\n",
        "        \"Proof by induction on n. Base case: When n = 0, 2â° = 1 â‰¥ 1 = 0 + 1. Inductive step: Assume 2^k â‰¥ k + 1. Then 2^(k+1) = 2Â·2^k â‰¥ 2(k+1) = 2k + 2 â‰¥ k + 2 = (k+1) + 1. By the principle of mathematical induction, 2^n â‰¥ n + 1 for all n â‰¥ 0.\",\n",
        "        \"We use strong induction. Base case: Fâ‚ = 1 < 2 = 2Â¹. Inductive step: Assume Fâ‚– < 2^k for all k < n. Then Fâ‚™ = Fâ‚™â‚‹â‚ + Fâ‚™â‚‹â‚‚ < 2^(n-1) + 2^(n-2) < 2^(n-1) + 2^(n-1) = 2^n. By strong induction, Fâ‚™ < 2^n for all n.\",\n",
        "        \"Proof by induction. Base case: For n = 1, we have 1Â² = 1 = 1(2)(3)/6. âœ“ Inductive step: Suppose 1Â² + 2Â² + ... + kÂ² = k(k+1)(2k+1)/6. Adding (k+1)Â², we get k(k+1)(2k+1)/6 + (k+1)Â² = (k+1)(k+2)(2k+3)/6. Done by induction.\",\n",
        "        \"We prove n! > 2^n for n â‰¥ 4 by induction. Base case: 4! = 24 > 16 = 2â´. Inductive step: Assume k! > 2^k for some k â‰¥ 4. Then (k+1)! = (k+1)Â·k! > (k+1)Â·2^k > 2Â·2^k = 2^(k+1). By mathematical induction, the result holds.\",\n",
        "        \"By induction on n. Base case: n = 1 gives 1 = 1. Inductive hypothesis: Assume the formula holds for n = k. Inductive step: For n = k + 1, we have... By the inductive hypothesis, this equals... Therefore by induction, the formula holds for all positive integers.\",\n",
        "        \"We prove by induction that nÂ³ - n is divisible by 6. Base case: When n = 1, nÂ³ - n = 0, which is divisible by 6. Inductive step: Assume kÂ³ - k â‰¡ 0 (mod 6). Then (k+1)Â³ - (k+1) = kÂ³ + 3kÂ² + 3k + 1 - k - 1 = (kÂ³ - k) + 3k(k+1). Since k(k+1) is even, 3k(k+1) â‰¡ 0 (mod 6). By induction, done.\",\n",
        "        \"Proof by induction. Base case: For n = 0, the empty product equals 1. Inductive step: Assume the result for n = k. For n = k + 1, by the inductive hypothesis... This completes the induction.\",\n",
        "        \"We use induction on the number of elements. Base case: A set with 0 elements has 2â° = 1 subset (the empty set). Inductive step: Assume a set with k elements has 2^k subsets. Adding one element doubles the subsets (each old subset with or without the new element). So 2Â·2^k = 2^(k+1) subsets.\",\n",
        "        \"By induction. Base case: n = 1 satisfies the inequality. Inductive hypothesis: Suppose the inequality holds for n = k. Inductive step: We must show it holds for n = k + 1. Using the inductive hypothesis... Therefore by mathematical induction, the inequality holds for all n â‰¥ 1.\",\n",
        "    ],\n",
        "\n",
        "    ProofTechnique.CASES: [\n",
        "        \"We prove nÂ² has the same parity as n. Case 1: Suppose n is even. Then n = 2k, so nÂ² = 4kÂ² = 2(2kÂ²), which is even. Case 2: Suppose n is odd. Then n = 2k + 1, so nÂ² = 4kÂ² + 4k + 1 = 2(2kÂ² + 2k) + 1, which is odd.\",\n",
        "        \"We consider two cases. Case 1: If x â‰¥ 0, then |x| = x â‰¥ 0. Case 2: If x < 0, then |x| = -x > 0. In both cases, |x| â‰¥ 0.\",\n",
        "        \"There are three cases to consider. Case i: n â‰¡ 0 (mod 3). Case ii: n â‰¡ 1 (mod 3). Case iii: n â‰¡ 2 (mod 3). In each case, we verify the claim holds.\",\n",
        "        \"We divide into cases based on the sign of x. First case: x > 0. Second case: x = 0. Third case: x < 0. Combining all cases, the result follows.\",\n",
        "        \"Proof by cases. Either n is divisible by 2, or n is not divisible by 2. In the first case... In the second case... Therefore the result holds in all cases.\",\n",
        "        \"We split into two cases depending on whether n is even or odd. Case 1: n = 2m for some integer m. Then... Case 2: n = 2m + 1 for some integer m. Then... This covers all possibilities.\",\n",
        "        \"Consider the cases separately. Case 1: Suppose a â‰¤ b. Then max(a,b) = b. Case 2: Suppose a > b. Then max(a,b) = a. In either case, max(a,b) â‰¥ a and max(a,b) â‰¥ b.\",\n",
        "        \"We analyze by cases. In the first case, assume xÂ² < 1. In the second case, assume xÂ² = 1. In the third case, assume xÂ² > 1. Each case leads to the desired conclusion.\",\n",
        "        \"There are two cases. If n is prime, then... If n is composite, then... Either way, the statement holds.\",\n",
        "        \"We proceed case by case. Case (a): the denominator is positive. Case (b): the denominator is negative. Note the denominator cannot be zero. Both cases yield the result.\",\n",
        "    ],\n",
        "\n",
        "    ProofTechnique.CONSTRUCTION: [\n",
        "        \"To show there exists an even prime, we exhibit 2. Indeed, 2 has exactly two divisors: 1 and 2. And 2 = 2Â·1 is even. Thus we have constructed an even prime.\",\n",
        "        \"We construct an explicit example. Let f(x) = xÂ². Then f is continuous everywhere but differentiable nowhere... Actually, let f(x) = |x|. At x = 0, f is continuous but not differentiable.\",\n",
        "        \"To prove existence, we construct: take n = 6. Then n = 2Â·3 = 1 + 2 + 3, showing 6 is both a product and sum of consecutive integers.\",\n",
        "        \"We exhibit a concrete example. Consider the matrix A = [[1, 2], [0, 1]]. Then AÂ² = [[1, 4], [0, 1]] â‰  I, showing A is not an involution but has determinant 1.\",\n",
        "        \"Such a number exists: namely, take x = âˆš2 + âˆš3. We verify that x is irrational and that xÂ² = 5 + 2âˆš6 is also irrational.\",\n",
        "        \"We construct the required function explicitly. Define f: â„ â†’ â„ by f(x) = xÂ³. This function is bijective, continuous, and satisfies f(-x) = -f(x).\",\n",
        "        \"To show a solution exists, we construct one. Let x = 2, y = 3, z = 1. Then xÂ² + yÂ² = 4 + 9 = 13 and zÂ² + 12 = 1 + 12 = 13. So (2, 3, 1) is a solution.\",\n",
        "        \"The following example demonstrates the claim. Take the sequence aâ‚™ = (-1)â¿/n. This sequence converges to 0 but is not monotonic.\",\n",
        "        \"We exhibit an explicit counterexample. Let A = {1, 2} and B = {2, 3}. Then A âˆª B = {1, 2, 3} has 3 elements, but |A| + |B| = 4. So |A âˆª B| â‰  |A| + |B| in general.\",\n",
        "        \"Consider the polynomial p(x) = xÂ² - 2. By construction, p(âˆš2) = 2 - 2 = 0, so âˆš2 is a root of p(x).\",\n",
        "    ],\n",
        "\n",
        "    ProofTechnique.CONTRAPOSITIVE: [\n",
        "        \"We prove the contrapositive: if n is odd, then nÂ² is odd. Suppose n = 2k + 1. Then nÂ² = 4kÂ² + 4k + 1 = 2(2kÂ² + 2k) + 1, which is odd. By contrapositive, if nÂ² is even, then n is even.\",\n",
        "        \"Instead of proving P â†’ Q directly, we prove the contrapositive Â¬Q â†’ Â¬P. Assume Â¬Q. Then... Therefore Â¬P. By contrapositive, P â†’ Q.\",\n",
        "        \"Proof by contrapositive. We show: if nÂ² is not divisible by 3, then n is not divisible by 3. Suppose 3 âˆ¤ nÂ². Then nÂ² â‰¡ 1 or 4 (mod 9), so n â‰¢ 0 (mod 3). Contrapositively, 3|n implies 3|nÂ².\",\n",
        "        \"We prove the contrapositive statement. If f is not continuous, then f is not differentiable. This is equivalent to: if f is differentiable, then f is continuous.\",\n",
        "        \"The contrapositive is: if xy is odd, then both x and y are odd. Suppose xy is odd. If x were even, xy would be even. So x must be odd. Similarly y is odd. By contrapositive, x or y even implies xy even.\",\n",
        "        \"Rather than prove directly, we prove the contrapositive. Assume the conclusion fails. Then... which implies the hypothesis fails. By contrapositive, the original implication holds.\",\n",
        "        \"Proof via contrapositive. Contrapositive statement: if not B, then not A. Assuming Â¬B, we derive... hence Â¬A. The contrapositive being true, the original statement A â†’ B follows.\",\n",
        "        \"We establish the contrapositive. If n is not prime, then 2â¿ - 1 is not prime. Let n = ab with 1 < a, b < n. Then 2â¿ - 1 = (2^a - 1)(2^a(b-1) + ... + 1). By contrapositive, 2â¿ - 1 prime implies n prime.\",\n",
        "    ],\n",
        "\n",
        "    ProofTechnique.DIRECT: [\n",
        "        \"Let n be an even integer. Then n = 2k for some integer k. Therefore nÂ² = 4kÂ² = 2(2kÂ²), which is clearly even. Thus the square of an even number is even.\",\n",
        "        \"Assume a | b and b | c. Then b = am and c = bn for some integers m, n. Therefore c = amn = a(mn), so a | c. This proves transitivity of divisibility.\",\n",
        "        \"Let x and y be rational numbers. Then x = a/b and y = c/d for integers a, b, c, d with b, d â‰  0. We have x + y = (ad + bc)/(bd). Since ad + bc and bd are integers and bd â‰  0, x + y is rational.\",\n",
        "        \"Suppose f and g are continuous at a. For any Îµ > 0, there exist Î´â‚, Î´â‚‚ > 0 such that... Taking Î´ = min(Î´â‚, Î´â‚‚), it follows that f + g is continuous at a.\",\n",
        "        \"Let A âŠ† B and B âŠ† C. Take any x âˆˆ A. Since A âŠ† B, we have x âˆˆ B. Since B âŠ† C, we have x âˆˆ C. Therefore A âŠ† C.\",\n",
        "        \"Assume n is divisible by 6. Then n = 6k for some integer k. We have n = 6k = 2(3k), so 2 | n. Also n = 6k = 3(2k), so 3 | n. Thus n is divisible by both 2 and 3.\",\n",
        "        \"Let f be differentiable at a. By definition, f'(a) = lim[hâ†’0] (f(a+h) - f(a))/h exists. Therefore f(a+h) - f(a) â†’ 0 as h â†’ 0, which means f is continuous at a.\",\n",
        "        \"We prove directly that the sum of two odd numbers is even. Let m = 2j + 1 and n = 2k + 1 be odd. Then m + n = 2j + 1 + 2k + 1 = 2(j + k + 1), which is even.\",\n",
        "    ],\n",
        "\n",
        "    ProofTechnique.EXHAUSTION: [\n",
        "        \"We verify by exhaustion. For n = 1: 1Â² = 1 âœ“. For n = 2: 2Â² = 4 âœ“. For n = 3: 3Â² = 9 âœ“. For n = 4: 4Â² = 16 âœ“. Having checked all cases, the claim holds.\",\n",
        "        \"By exhaustive case checking: 0Â² mod 4 = 0, 1Â² mod 4 = 1, 2Â² mod 4 = 0, 3Â² mod 4 = 1. So squares are â‰¡ 0 or 1 (mod 4).\",\n",
        "        \"Since there are only finitely many possibilities, we enumerate all of them. Checking each one... Therefore the claim holds.\",\n",
        "        \"We verify the identity for all 8 possible combinations of signs. (+,+,+): ... (+,+,-): ... And so on. By exhaustion, the identity holds in all cases.\",\n",
        "        \"The only divisors of 12 are 1, 2, 3, 4, 6, 12. Checking each: 1+2+3+4+6 = 16 > 12. So 12 is abundant.\",\n",
        "        \"We check all n from 1 to 100 by brute force computation. The only solutions are n = 1, 8, and 17.\",\n",
        "        \"Since n âˆˆ {1, 2, 3, 4, 5}, we check each case exhaustively. For n=1: valid. For n=2: valid. For n=3: invalid. For n=4: valid. For n=5: invalid. Thus n âˆˆ {1, 2, 4}.\",\n",
        "        \"Enumerate all permutations of {1, 2, 3}: (1,2,3), (1,3,2), (2,1,3), (2,3,1), (3,1,2), (3,2,1). Exactly 2 of these satisfy the constraint.\",\n",
        "    ],\n",
        "}\n",
        "\n",
        "print(\"âœ… Sample proofs defined\")\n",
        "for technique, proofs in SAMPLE_PROOFS.items():\n",
        "    print(f\"   {TECHNIQUE_NAMES[technique]}: {len(proofs)} examples\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… Created 66 training examples\n",
            "   Label distribution: {np.int64(0): np.int64(8), np.int64(1): np.int64(12), np.int64(2): np.int64(10), np.int64(3): np.int64(8), np.int64(4): np.int64(10), np.int64(5): np.int64(10), np.int64(6): np.int64(8)}\n"
          ]
        }
      ],
      "source": [
        "def apply_labeling_functions(text: str) -> int:\n",
        "    \"\"\"\n",
        "    Apply all labeling functions and return majority vote.\n",
        "    Returns ABSTAIN (-1) if no clear winner.\n",
        "    \"\"\"\n",
        "    votes = {}\n",
        "    total_weight = 0\n",
        "\n",
        "    for lf in LABELING_FUNCTIONS:\n",
        "        label = lf(text)\n",
        "        if label != ProofTechnique.ABSTAIN:\n",
        "            votes[label] = votes.get(label, 0) + lf.weight\n",
        "            total_weight += lf.weight\n",
        "\n",
        "    if not votes:\n",
        "        return ProofTechnique.ABSTAIN\n",
        "\n",
        "    return max(votes.keys(), key=lambda k: votes[k])\n",
        "\n",
        "\n",
        "# Create training data\n",
        "train_texts = []\n",
        "train_labels = []\n",
        "\n",
        "for technique, proofs in SAMPLE_PROOFS.items():\n",
        "    for proof in proofs:\n",
        "        # Use the ground truth label (from our curated examples)\n",
        "        train_texts.append(proof)\n",
        "        train_labels.append(int(technique))\n",
        "\n",
        "print(f\"âœ… Created {len(train_texts)} training examples\")\n",
        "print(f\"   Label distribution: {dict(zip(*np.unique(train_labels, return_counts=True)))}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 3: Generate Embeddings\n",
        "\n",
        "Convert proof text â†’ 384-dimensional vectors using a pre-trained sentence transformer."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/homebrew/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading sentence transformer model...\n",
            "âœ… Model loaded\n",
            "\n",
            "Generating embeddings...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Batches: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:04<00:00,  1.62s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… Generated embeddings with shape: (66, 384)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "from sentence_transformers import SentenceTransformer\n",
        "\n",
        "print(\"Loading sentence transformer model...\")\n",
        "encoder = SentenceTransformer('all-MiniLM-L6-v2')\n",
        "print(\"âœ… Model loaded\")\n",
        "\n",
        "print(\"\\nGenerating embeddings...\")\n",
        "X_embeddings = encoder.encode(train_texts, show_progress_bar=True)\n",
        "print(f\"âœ… Generated embeddings with shape: {X_embeddings.shape}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 4: Train Classifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training classifiers...\n",
            "\n",
            "Logistic Regression:\n",
            "   Cross-val accuracy: 66.7% (+/- 18.0%)\n",
            "MLP (Neural Network):\n",
            "   Cross-val accuracy: 77.4% (+/- 27.1%)\n",
            "\n",
            "âœ… Best model: MLP (Neural Network) (77.4% accuracy)\n",
            "\n",
            "Training final MLP (Neural Network) on all data...\n",
            "âœ… Training complete\n"
          ]
        }
      ],
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Encode labels\n",
        "label_encoder = LabelEncoder()\n",
        "y_encoded = label_encoder.fit_transform(train_labels)\n",
        "\n",
        "print(\"Training classifiers...\\n\")\n",
        "\n",
        "# Try both Logistic Regression and MLP\n",
        "classifiers = {\n",
        "    \"Logistic Regression\": LogisticRegression(max_iter=1000, random_state=42),\n",
        "    \"MLP (Neural Network)\": MLPClassifier(hidden_layer_sizes=(128, 64), max_iter=500, random_state=42)\n",
        "}\n",
        "\n",
        "best_clf = None\n",
        "best_score = 0\n",
        "best_name = \"\"\n",
        "\n",
        "for name, clf in classifiers.items():\n",
        "    scores = cross_val_score(clf, X_embeddings, y_encoded, cv=5)\n",
        "    mean_score = scores.mean()\n",
        "    print(f\"{name}:\")\n",
        "    print(f\"   Cross-val accuracy: {mean_score:.1%} (+/- {scores.std()*2:.1%})\")\n",
        "\n",
        "    if mean_score > best_score:\n",
        "        best_score = mean_score\n",
        "        best_clf = clf\n",
        "        best_name = name\n",
        "\n",
        "print(f\"\\nâœ… Best model: {best_name} ({best_score:.1%} accuracy)\")\n",
        "\n",
        "# Train final model on all data\n",
        "print(f\"\\nTraining final {best_name} on all data...\")\n",
        "best_clf.fit(X_embeddings, y_encoded)\n",
        "print(\"âœ… Training complete\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 5: Test the Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Testing on new proofs:\n",
            "\n",
            "======================================================================\n",
            "Proof: Suppose for contradiction that âˆš7 is rational. Then âˆš7 = a/b in lowest terms. So...\n",
            "Predicted: Proof by Contradiction\n",
            "Confidence: 99.6%\n",
            "----------------------------------------------------------------------\n",
            "Proof: We prove by induction. Base case: For n=0, the sum is 0 = 0(0+1)/2. Inductive st...\n",
            "Predicted: Mathematical Induction\n",
            "Confidence: 99.6%\n",
            "----------------------------------------------------------------------\n",
            "Proof: Consider two cases. Case 1: If x > 0, then |x| = x, so |x|/x = 1. Case 2: If x <...\n",
            "Predicted: Proof by Cases\n",
            "Confidence: 97.6%\n",
            "----------------------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "# Test on new proofs\n",
        "test_proofs = [\n",
        "    \"Suppose for contradiction that âˆš7 is rational. Then âˆš7 = a/b in lowest terms. So 7bÂ² = aÂ², meaning 7|a. Let a = 7k. Then 7bÂ² = 49kÂ², so bÂ² = 7kÂ², meaning 7|b. But this contradicts a/b being in lowest terms. Hence âˆš7 is irrational.\",\n",
        "    \"We prove by induction. Base case: For n=0, the sum is 0 = 0(0+1)/2. Inductive step: Assume true for k. Then 0+1+...+k+(k+1) = k(k+1)/2 + (k+1) = (k+1)(k+2)/2. By induction, done.\",\n",
        "    \"Consider two cases. Case 1: If x > 0, then |x| = x, so |x|/x = 1. Case 2: If x < 0, then |x| = -x, so |x|/x = -1. Thus |x|/x = Â±1 for all x â‰  0.\",\n",
        "]\n",
        "\n",
        "print(\"Testing on new proofs:\\n\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "for proof in test_proofs:\n",
        "    embedding = encoder.encode([proof])\n",
        "    pred_encoded = best_clf.predict(embedding)[0]\n",
        "    pred_label = label_encoder.inverse_transform([pred_encoded])[0]\n",
        "    proba = best_clf.predict_proba(embedding)[0]\n",
        "    confidence = proba[pred_encoded]\n",
        "\n",
        "    print(f\"Proof: {proof[:80]}...\")\n",
        "    print(f\"Predicted: {TECHNIQUE_NAMES[pred_label]}\")\n",
        "    print(f\"Confidence: {confidence:.1%}\")\n",
        "    print(\"-\" * 70)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 6: Save Model Files\n",
        "\n",
        "Download these files and put them in your `backend/models/` folder."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… Saved models/classifier.pkl\n",
            "âœ… Saved models/label_encoder.pkl\n",
            "âœ… Saved models/config.json\n",
            "\n",
            "==================================================\n",
            "MODEL SUMMARY\n",
            "==================================================\n",
            "model_name: all-MiniLM-L6-v2\n",
            "embedding_dim: 384\n",
            "classifier_type: MLP (Neural Network)\n",
            "num_classes: 7\n",
            "classes: ['Direct Proof', 'Proof by Contradiction', 'Mathematical Induction', 'Contrapositive', 'Proof by Construction', 'Proof by Cases', 'Proof by Exhaustion']\n",
            "training_samples: 66\n",
            "cv_accuracy: 0.7736263736263737\n"
          ]
        }
      ],
      "source": [
        "import pickle\n",
        "import json\n",
        "import os\n",
        "\n",
        "# Create models directory\n",
        "os.makedirs('models', exist_ok=True)\n",
        "\n",
        "# Save classifier\n",
        "with open('models/classifier.pkl', 'wb') as f:\n",
        "    pickle.dump(best_clf, f)\n",
        "print(\"âœ… Saved models/classifier.pkl\")\n",
        "\n",
        "# Save label encoder\n",
        "with open('models/label_encoder.pkl', 'wb') as f:\n",
        "    pickle.dump(label_encoder, f)\n",
        "print(\"âœ… Saved models/label_encoder.pkl\")\n",
        "\n",
        "# Save config\n",
        "config = {\n",
        "    \"model_name\": \"all-MiniLM-L6-v2\",\n",
        "    \"embedding_dim\": 384,\n",
        "    \"classifier_type\": best_name,\n",
        "    \"num_classes\": len(label_encoder.classes_),\n",
        "    \"classes\": [TECHNIQUE_NAMES[int(c)] for c in label_encoder.classes_],\n",
        "    \"training_samples\": len(train_texts),\n",
        "    \"cv_accuracy\": float(best_score)\n",
        "}\n",
        "with open('models/config.json', 'w') as f:\n",
        "    json.dump(config, f, indent=2)\n",
        "print(\"âœ… Saved models/config.json\")\n",
        "\n",
        "print(\"\\n\" + \"=\" * 50)\n",
        "print(\"MODEL SUMMARY\")\n",
        "print(\"=\" * 50)\n",
        "for k, v in config.items():\n",
        "    print(f\"{k}: {v}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'google'",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[12]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Download the model files\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mgoogle\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcolab\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m files\n\u001b[32m      4\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mğŸ“¥ Downloading model files...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      5\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m   (Save these to your backend/models/ folder)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
            "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'google'"
          ]
        }
      ],
      "source": [
        "# Download the model files\n",
        "\n",
        "print(\"ğŸ“¥ Downloading model files...\")\n",
        "print(\"   (Save these to your backend/models/ folder)\\n\")\n",
        "\n",
        "files.download('models/classifier.pkl')\n",
        "files.download('models/label_encoder.pkl')\n",
        "files.download('models/config.json')\n",
        "\n",
        "print(\"\\nâœ… Done!\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
